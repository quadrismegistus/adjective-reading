{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d2eb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q -r requirements.txt\n",
    "from __reading import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c891e66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "CORPUS_DATA = None\n",
    "def get_corpus_data(path_corpus=PATH_CORPUS):\n",
    "    def without_full_text(d):\n",
    "        return {k: v for k, v in d.items() if k != 'fullText'}\n",
    "\n",
    "    global CORPUS_DATA\n",
    "    if CORPUS_DATA is None:\n",
    "        CORPUS_DATA = pd.DataFrame(\n",
    "            tqdm(\n",
    "                (without_full_text(d) for d in orjsonl.stream(path_corpus)),\n",
    "                total=CORPUS_NUM_SENTS\n",
    "            )\n",
    "        ).set_index('url')\n",
    "    return CORPUS_DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc4ba8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corpus = get_corpus_data()\n",
    "df_instances = get_instances_data()\n",
    "word2data = get_word2data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7e14ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df = df_instances.merge(df_corpus, on=\"url\", how=\"left\").fillna(\"\")\n",
    "total_df['year'] = pd.to_numeric(total_df.publicationYear, errors=\"coerce\")\n",
    "total_df['decade'] = total_df.year.astype(int) // 10 * 10\n",
    "total_df['prev_pos'] = total_df.token0.map(lambda x: word2data[x]['pos'] if x in word2data else None).fillna(\"\")\n",
    "total_df['next_pos'] = total_df.token2.map(lambda x: word2data[x]['pos'] if x in word2data else None).fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943d2a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df_adjs = total_df[total_df.prev_pos.str.startswith(\"j\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fedfe7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df_adjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa5f0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_decade_counts(df, max_rank=100):\n",
    "    new_ld = []\n",
    "    for decade, decade_df in df.groupby('decade'):\n",
    "        tok_counts = decade_df.token0.value_counts()\n",
    "        tok_rel_freq = tok_counts / tok_counts.sum()\n",
    "        \n",
    "        for rank, (tok, rel_freq) in enumerate(tok_rel_freq.items()):\n",
    "            if rank >= max_rank:\n",
    "                break\n",
    "\n",
    "            tok_df = decade_df[decade_df.token0 == tok]\n",
    "            sents = tok_df.sent.tolist()\n",
    "\n",
    "            decade_d = {\n",
    "                'decade': decade,\n",
    "                'token': tok,\n",
    "                'rank': rank+1,\n",
    "                'count': tok_counts[tok],\n",
    "                'freq': rel_freq,\n",
    "                \"sents\": sents,\n",
    "                \n",
    "            }\n",
    "            new_ld.append(decade_d)\n",
    "    new_df = pd.DataFrame(new_ld)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcad4b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "decade_word_counts = get_decade_counts(total_df_adjs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b344c1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1a783d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9922b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install plotnine\n",
    "import plotnine as p9\n",
    "p9.options.figure_size = (10, 6)\n",
    "p9.options.dpi = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff5ee01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecf274a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20e3b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_ever_top_words = new_df.groupby('token')['count'].sum().sort_values(ascending=False).index.tolist()\n",
    "print(\"distant\" in most_ever_top_words)\n",
    "\n",
    "\n",
    "fig_num_words = 50\n",
    "fig_top_words = most_ever_top_words[:fig_num_words]\n",
    "print(\"distant\" in fig_top_words)\n",
    "\n",
    "ever_top_words_sorted = token2historical_avg.sort_values().index.tolist()\n",
    "# ever_top_words_sorted = fig_top_words\n",
    "fig_df = new_df.query('token in @fig_top_words').copy()\n",
    "fig_df['fpk'] = fig_df['freq'] * 1000\n",
    "fig_df['historical_avg'] = fig_df['token'].map(token2historical_avg)\n",
    "\n",
    "token_labels = [\n",
    "    f\"{token} ({int(token2historical_avg[token])})\"\n",
    "    for token in ever_top_words_sorted\n",
    "    if token in fig_top_words\n",
    "]\n",
    "\n",
    "token_labels\n",
    "\n",
    "\n",
    "fig_df['token_label'] = fig_df.apply(lambda row: f\"{row['token']} ({int(row['historical_avg'])})\", axis=1)\n",
    "\n",
    "fig_df['token'] = pd.Categorical(fig_df['token'], categories=ever_top_words_sorted, ordered=True)\n",
    "fig_df['token_label'] = pd.Categorical(fig_df['token_label'], categories=token_labels, ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f97d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = p9.ggplot(fig_df, p9.aes(x=\"decade\", y=\"fpk\", group=\"token\"))\n",
    "fig += p9.geom_line(size=.5, alpha=.15, color=\"blue\")\n",
    "fig += p9.geom_point(p9.aes(size=\"count\"), alpha=.15, color=\"blue\")\n",
    "fig += p9.geom_text(p9.aes(label=\"count\"), size=8, angle=45)\n",
    "fig += p9.facet_wrap(\"token_label\", ncol=10)\n",
    "fig += p9.theme_classic()\n",
    "fig += p9.theme(figure_size=(16, 9))\n",
    "fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9400ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts = new_df.groupby('token')['count'].sum()\n",
    "word_freqsum = new_df.groupby('token')['freq'].sum()\n",
    "word_freqavg = new_df.groupby('token')['freq'].mean()\n",
    "word_freqmax = new_df.groupby('token')['freq'].max()\n",
    "word_ld =[]\n",
    "for word in token2historical_avg.index:\n",
    "    word_d = {\n",
    "        \"token\": word,\n",
    "        \"count_sum\": word_counts[word],\n",
    "        \"freq_sum\": word_freqsum[word],\n",
    "        \"freq_avg\": word_freqavg[word],\n",
    "        \"freq_max\": word_freqmax[word],\n",
    "        \"historical_avg\": int(token2historical_avg[word]),\n",
    "    }\n",
    "    word_ld.append(word_d)\n",
    "word_df = pd.DataFrame(word_ld)\n",
    "word_df['freq'] = word_df['freq_sum']\n",
    "word_df['fpk_max'] = word_df['freq_max'] * 1000\n",
    "word_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ae6dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_fig_df = word_df[word_df.count_sum > 10]\n",
    "# print(\"distant\" in word_fig_df.token.tolist())\n",
    "fig = p9.ggplot(word_fig_df, p9.aes(x=\"historical_avg\", y=\"fpk_max\"))\n",
    "fig += p9.geom_text(p9.aes(label=\"token\"), size=12)\n",
    "fig += p9.theme_minimal()\n",
    "fig += p9.theme(figure_size=(16, 9))\n",
    "fig += p9.scale_y_log10()\n",
    "fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a933a4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_df.to_csv('word_stats.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1aa372",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df_adjs.decade #.query('token0 == \"distant\"').sent.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc13ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df_adjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2042d7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "grp,grpdf = next((g,grpdf) for g,grpdf in total_df_adjs.groupby(['decade','token0']) if g[1] == \"distant\")\n",
    "grpdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcd7294",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(grpdf.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501f29b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict(total_df_adjs.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29576f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eg_str(word_decade_df, max_sents=10):\n",
    "    egdf = word_decade_df if len(word_decade_df) <= max_sents else word_decade_df.sample(max_sents)\n",
    "\n",
    "    egs = []\n",
    "    for grp, grpdf in egdf.groupby('url'):\n",
    "        row = grpdf.iloc[0]\n",
    "        author = row.creator\n",
    "        if len(row.creator) > 1:\n",
    "            author += \" et al.\"\n",
    "        title = row.title\n",
    "        year = row.year\n",
    "        journal = row.isPartOf\n",
    "        vol = row.volumeNumber\n",
    "        issue = row.issueNumber\n",
    "        this_eg = [f'{author}, \"{title}\", _{journal}_, vol. {vol}, no. {issue} ({year})']\n",
    "        for sent in grpdf.sent.tolist():\n",
    "            this_eg.append(f'  * {sent}')\n",
    "        egs.append(\"\\n\".join(this_eg))\n",
    "    return '\\n\\n'.join(egs)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12acb4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_df_adjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909fe7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_decade_to_egs = {\n",
    "    (decade, word): get_eg_str(word_decade_df)\n",
    "    for (decade, word), word_decade_df in total_df_adjs.groupby(['decade','token0'])\n",
    "}\n",
    "\n",
    "out_df = new_df.copy()\n",
    "out_df['egs'] = out_df.apply(lambda row: word_decade_to_egs[(row.decade, row.token)], axis=1)\n",
    "\n",
    "out_df = out_df.merge(word_df, on='token', how='left', suffixes=('', '_word'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7c0efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89236f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install openpyxl\n",
    "out_df.to_excel('word_decade_stats.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39e4d96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
